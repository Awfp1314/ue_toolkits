# -*- coding: utf-8 -*-

"""
æœ¬åœ°æ–‡æ¡£æ£€ç´¢å™¨
åŸºäº Chroma å‘é‡æ•°æ®åº“çš„æœ¬åœ°çŸ¥è¯†æ£€ç´¢
"""

import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
from core.logger import get_logger
from core.ai_services import EmbeddingService

# å»¶è¿Ÿè·å– logger
def _get_logger():
    return get_logger(__name__)

logger = None


class BGEEmbeddingFunction:
    """
    é€‚é… ChromaDB çš„åµŒå…¥å‡½æ•°åŒ…è£…å™¨
    ä½¿ç”¨ç»Ÿä¸€çš„ EmbeddingService (bge-small-zh-v1.5)
    """
    
    def __init__(self, embedding_service: EmbeddingService):
        """
        åˆå§‹åŒ–åµŒå…¥å‡½æ•°
        
        Args:
            embedding_service: ç»Ÿä¸€çš„åµŒå…¥æœåŠ¡å®ä¾‹
        """
        self.embedding_service = embedding_service
    
    def name(self) -> str:
        """ChromaDB éœ€è¦çš„æ–¹æ³•ï¼ˆä¸æ˜¯å±æ€§ï¼‰"""
        return "bge-small-zh-v1.5"
    
    def __call__(self, input: List[str]) -> List[List[float]]:
        """
        ChromaDB è¦æ±‚çš„æ¥å£ï¼šæ¥æ”¶æ–‡æœ¬åˆ—è¡¨ï¼Œè¿”å›å‘é‡åˆ—è¡¨
        
        Args:
            input: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            List[List[float]]: å‘é‡åˆ—è¡¨
        """
        # ä½¿ç”¨ EmbeddingService æ‰¹é‡ç¼–ç 
        embeddings = self.embedding_service.encode_text(input, convert_to_numpy=False)
        
        if embeddings is None:
            # å¦‚æœç¼–ç å¤±è´¥ï¼Œè¿”å›é›¶å‘é‡
            dimension = self.embedding_service.get_embedding_dimension() or 384
            return [[0.0] * dimension for _ in input]
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼ˆChromaDB éœ€è¦ï¼‰
        if hasattr(embeddings, 'tolist'):
            return embeddings.tolist()
        return list(embeddings)


class LocalDocIndex:
    """
    æœ¬åœ°æ–‡æ¡£ç´¢å¼•
    
    åŸºäº Chroma å‘é‡æ•°æ®åº“ï¼Œç”¨äºæ£€ç´¢æœ¬åœ°æ–‡æ¡£ã€READMEã€é…ç½®æ¨¡æ¿ç­‰
    """
    
    def __init__(self, db_path: Optional[Path] = None, embedding_service: Optional[EmbeddingService] = None):
        """
        åˆå§‹åŒ–æœ¬åœ°æ–‡æ¡£ç´¢å¼•
        
        Args:
            db_path: Chroma æ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤ç”± PathUtils æä¾›ï¼‰
            embedding_service: åµŒå…¥æœåŠ¡å®ä¾‹ï¼ˆé»˜è®¤åˆ›å»ºæ–°å®ä¾‹ï¼‰
        """
        self.logger = _get_logger()  # å»¶è¿Ÿè·å–
        
        # æ•°æ®åº“è·¯å¾„
        if db_path is None:
            try:
                from core.utils.path_utils import PathUtils
                path_utils = PathUtils()
                self.db_path = path_utils.get_user_data_dir() / "chroma_db"
            except Exception as e:
                self.logger.warning(f"æ— æ³•è·å–ç”¨æˆ·æ•°æ®ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„: {e}")
                self.db_path = Path.home() / ".ue_toolkit" / "chroma_db"
        else:
            self.db_path = db_path
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.db_path.mkdir(parents=True, exist_ok=True)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ EmbeddingServiceï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
        self.embedding_service = embedding_service or EmbeddingService()
        
        # åˆ›å»ºé€‚é… ChromaDB çš„åµŒå…¥å‡½æ•°
        self._embedding_function = BGEEmbeddingFunction(self.embedding_service)
        
        # å»¶è¿Ÿåˆå§‹åŒ– Chromaï¼ˆé¿å…å¯åŠ¨æ—¶åŠ è½½ï¼‰
        self._client = None
        self._collection = None
        
        self.logger.info(f"æœ¬åœ°æ–‡æ¡£ç´¢å¼•åˆå§‹åŒ–ï¼ˆæ•°æ®åº“è·¯å¾„: {self.db_path}ï¼Œä½¿ç”¨ç»Ÿä¸€åµŒå…¥æœåŠ¡ï¼‰")
    
    def _init_chroma(self):
        """å»¶è¿Ÿåˆå§‹åŒ– Chroma å®¢æˆ·ç«¯"""
        if self._client is not None:
            return
        
        try:
            import chromadb
            from chromadb.config import Settings
            
            # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
            self._client = chromadb.PersistentClient(
                path=str(self.db_path),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            
            # è·å–æˆ–åˆ›å»ºé›†åˆï¼ˆä½¿ç”¨ get_or_createï¼Œè®© ChromaDB å¤„ç†å†²çªï¼‰
            self._collection = self._client.get_or_create_collection(
                name="ue_toolkit_docs",
                metadata={"description": "UE Toolkit local documentation index (bge-small-zh-v1.5)"},
                embedding_function=self._embedding_function
            )
            self.logger.info(f"æ–‡æ¡£é›†åˆå·²å°±ç»ª: ue_toolkit_docs")
            
            # ä¸è°ƒç”¨ count()ï¼Œé¿å…è§¦å‘å´©æºƒ
            self.logger.info(f"Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨ bge-small-zh-v1.5ï¼‰")
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ– Chroma å¤±è´¥: {e}", exc_info=True)
            raise
    
    def upsert_docs(self, docs: List[Dict[str, Any]]):
        """
        æ’å…¥æˆ–æ›´æ–°æ–‡æ¡£åˆ°ç´¢å¼•
        
        Args:
            docs: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å« {'id', 'content', 'metadata'}
                 ä¾‹å¦‚ï¼š[{
                     'id': 'doc_1',
                     'content': 'æ–‡æ¡£å†…å®¹...',
                     'metadata': {'source': 'README.md', 'path': '/path/to/file'}
                 }]
        """
        try:
            self._init_chroma()
            
            if not docs:
                self.logger.warning("æ–‡æ¡£åˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡ç´¢å¼•")
                return
            
            # å‡†å¤‡æ•°æ®
            ids = [doc['id'] for doc in docs]
            documents = [doc['content'] for doc in docs]
            metadatas = [doc.get('metadata', {}) for doc in docs]
            
            # æ·»åŠ æ—¶é—´æˆ³
            for metadata in metadatas:
                metadata['indexed_at'] = datetime.now().isoformat()
            
            # æ‰¹é‡æ’å…¥
            self._collection.upsert(
                ids=ids,
                documents=documents,
                metadatas=metadatas
            )
            
            self.logger.info(f"æˆåŠŸç´¢å¼• {len(docs)} ä¸ªæ–‡æ¡£")
            
        except Exception as e:
            self.logger.error(f"ç´¢å¼•æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
    
    def search(self, query: str, top_k: int = 5, filter_metadata: Optional[Dict] = None) -> List[Dict[str, Any]]:
        """
        æœç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            filter_metadata: å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªç»“æœåŒ…å« {'content', 'metadata', 'distance'}
        """
        try:
            self._init_chroma()
            
            self.logger.info(f"ğŸ“š [æ–‡æ¡£å‘é‡æ£€ç´¢] å¯åŠ¨ ChromaDB æ–‡æ¡£è¯­ä¹‰æœç´¢ï¼ˆæŸ¥è¯¢: '{query[:30]}...'ï¼‰")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            results = self._collection.query(
                query_texts=[query],
                n_results=top_k,
                where=filter_metadata
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            
            if results['documents'] and len(results['documents']) > 0:
                for i in range(len(results['documents'][0])):
                    formatted_results.append({
                        'content': results['documents'][0][i],
                        'metadata': results['metadatas'][0][i] if results['metadatas'] else {},
                        'distance': results['distances'][0][i] if results['distances'] else 0.0
                    })
            
            if formatted_results:
                self.logger.info(f"âœ… [æ–‡æ¡£å‘é‡æ£€ç´¢] ChromaDB æˆåŠŸæ£€ç´¢åˆ° {len(formatted_results)} ä¸ªç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
            else:
                self.logger.info("âš ï¸ [æ–‡æ¡£å‘é‡æ£€ç´¢] ChromaDB æœªæ‰¾åˆ°åŒ¹é…æ–‡æ¡£")
            
            return formatted_results
            
        except Exception as e:
            self.logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
            return []
    
    def index_project_docs(self, project_root: Path):
        """
        ç´¢å¼•é¡¹ç›®æ–‡æ¡£
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        try:
            docs_to_index = []
            
            # 1. ç´¢å¼• docs/ ç›®å½•
            docs_dir = project_root / "docs"
            if docs_dir.exists():
                docs_to_index.extend(self._scan_directory(docs_dir, "docs"))
            
            # 2. ç´¢å¼• README.md æ–‡ä»¶
            readme_files = [
                project_root / "README.md",
                project_root / "Ue_Toolkitä½¿ç”¨æ–‡æ¡£.md",
                project_root / "è™šå¹»èµ„äº§å·¥å…·ç®±ä½¿ç”¨æ–‡æ¡£.md"
            ]
            for readme in readme_files:
                if readme.exists():
                    docs_to_index.extend(self._index_file(readme, "readme"))
            
            # 3. ç´¢å¼•æ¨¡å— README
            modules_dir = project_root / "modules"
            if modules_dir.exists():
                for module_dir in modules_dir.iterdir():
                    if module_dir.is_dir():
                        module_readme = module_dir / "README.md"
                        if module_readme.exists():
                            docs_to_index.extend(self._index_file(module_readme, f"module:{module_dir.name}"))
            
            # 4. ç´¢å¼•é…ç½®æ¨¡æ¿æè¿°
            config_templates_dir = project_root / "core" / "config_templates"
            if config_templates_dir.exists():
                docs_to_index.extend(self._scan_directory(config_templates_dir, "config_template"))
            
            # æ‰§è¡Œæ‰¹é‡ç´¢å¼•
            if docs_to_index:
                self.upsert_docs(docs_to_index)
                self.logger.info(f"é¡¹ç›®æ–‡æ¡£ç´¢å¼•å®Œæˆï¼Œå…± {len(docs_to_index)} ä¸ªæ–‡æ¡£")
            else:
                self.logger.warning("æœªæ‰¾åˆ°å¯ç´¢å¼•çš„æ–‡æ¡£")
            
        except Exception as e:
            self.logger.error(f"ç´¢å¼•é¡¹ç›®æ–‡æ¡£å¤±è´¥: {e}", exc_info=True)
    
    def _scan_directory(self, directory: Path, source_type: str) -> List[Dict[str, Any]]:
        """æ‰«æç›®å½•å¹¶å‡†å¤‡æ–‡æ¡£"""
        docs = []
        
        try:
            for file_path in directory.rglob("*.md"):
                docs.extend(self._index_file(file_path, source_type))
            
            # ä¹Ÿç´¢å¼• .txt æ–‡ä»¶
            for file_path in directory.rglob("*.txt"):
                docs.extend(self._index_file(file_path, source_type))
                
        except Exception as e:
            self.logger.error(f"æ‰«æç›®å½•å¤±è´¥: {e}")
        
        return docs
    
    def _index_file(self, file_path: Path, source_type: str) -> List[Dict[str, Any]]:
        """ç´¢å¼•å•ä¸ªæ–‡ä»¶ï¼ˆåˆ†æ®µï¼‰"""
        docs = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŒ‰æ®µè½åˆ†å‰²ï¼ˆé¿å…å•ä¸ªæ–‡æ¡£è¿‡å¤§ï¼‰
            chunks = self._split_content(content, max_length=1000)
            
            for i, chunk in enumerate(chunks):
                doc_id = f"{file_path.stem}_{i}_{hash(chunk) % 100000}"
                
                docs.append({
                    'id': doc_id,
                    'content': chunk,
                    'metadata': {
                        'source': str(file_path.name),
                        'path': str(file_path),
                        'source_type': source_type,
                        'chunk_index': i,
                        'total_chunks': len(chunks)
                    }
                })
        
        except Exception as e:
            self.logger.error(f"ç´¢å¼•æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return docs
    
    def _split_content(self, content: str, max_length: int = 1000) -> List[str]:
        """åˆ†å‰²é•¿æ–‡æœ¬ä¸ºå¤šä¸ªæ®µè½"""
        if len(content) <= max_length:
            return [content]
        
        # æŒ‰æ®µè½åˆ†å‰²
        paragraphs = content.split('\n\n')
        
        chunks = []
        current_chunk = ""
        
        for para in paragraphs:
            if len(current_chunk) + len(para) <= max_length:
                current_chunk += para + "\n\n"
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks if chunks else [content[:max_length]]
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç´¢å¼•ç»Ÿè®¡ä¿¡æ¯
        
        æ³¨æ„ï¼šä¸è°ƒç”¨ count()ï¼Œå› ä¸ºä¼šå¯¼è‡´å´©æºƒ
        """
        try:
            self._init_chroma()
            
            return {
                'total_documents': 'N/A',  # ä¸è°ƒç”¨ count() é¿å…å´©æºƒ
                'db_path': str(self.db_path),
                'collection_name': self._collection.name if self._collection else None,
                'status': 'active'
            }
        except Exception as e:
            self.logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {'total_documents': 'N/A', 'db_path': str(self.db_path), 'status': 'error'}

