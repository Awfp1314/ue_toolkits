# -*- coding: utf-8 -*-

"""
å¢å¼ºå‹è®°å¿†ç®¡ç†å™¨ï¼ˆåŸºäº Mem0 æ¦‚å¿µï¼‰
æä¾›å¤šçº§è®°å¿†ã€å‘é‡æ£€ç´¢å’Œæ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†
"""

import json
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime
from collections import deque
from core.logger import get_logger
from core.ai_services import EmbeddingService

# å»¶è¿Ÿè·å– loggerï¼Œé¿å…æ¨¡å—å¯¼å…¥æ—¶å¡ä½
def _get_logger():
    return get_logger(__name__)

logger = None  # å»¶è¿Ÿåˆå§‹åŒ–


class BGEEmbeddingFunctionForMemory:
    """
    é€‚é… ChromaDB çš„åµŒå…¥å‡½æ•°åŒ…è£…å™¨ï¼ˆè®°å¿†ä¸“ç”¨ï¼‰
    é¿å…å¾ªç¯å¯¼å…¥ local_retriever
    """
    
    def __init__(self, embedding_service):
        self.embedding_service = embedding_service
    
    def name(self) -> str:
        """ChromaDB éœ€è¦çš„æ–¹æ³•ï¼ˆä¸æ˜¯å±æ€§ï¼‰"""
        return "bge-small-zh-v1.5-memory"
    
    def __call__(self, input: List[str]) -> List[List[float]]:
        """ChromaDB æ‰¹é‡åµŒå…¥æ¥å£"""
        embeddings = self.embedding_service.encode_text(input, convert_to_numpy=False)
        
        if embeddings is None:
            dimension = self.embedding_service.get_embedding_dimension() or 384
            return [[0.0] * dimension for _ in input]
        
        if hasattr(embeddings, 'tolist'):
            return embeddings.tolist()
        return list(embeddings)
    
    def embed_query(self, input: str) -> List[float]:
        """ChromaDB æŸ¥è¯¢åµŒå…¥æ¥å£ï¼ˆå•ä¸ªæ–‡æœ¬ï¼‰"""
        # è°ƒç”¨æ‰¹é‡æ¥å£ï¼Œå–ç¬¬ä¸€ä¸ªç»“æœ
        result = self.__call__([input])
        return result[0] if result else []


class MemoryLevel:
    """è®°å¿†çº§åˆ«æšä¸¾"""
    USER = "user"           # ç”¨æˆ·çº§ï¼ˆè·¨ä¼šè¯æŒä¹…åŒ–ï¼‰
    SESSION = "session"     # ä¼šè¯çº§ï¼ˆå½“å‰ä¼šè¯ï¼‰
    CONTEXT = "context"     # ä¸Šä¸‹æ–‡çº§ï¼ˆæœ€è¿‘å‡ è½®ï¼‰


class Memory:
    """è®°å¿†é¡¹"""
    
    def __init__(self, content: str, level: str = MemoryLevel.SESSION, 
                 metadata: Optional[Dict] = None, timestamp: Optional[str] = None):
        self.content = content
        self.level = level
        self.metadata = metadata or {}
        self.timestamp = timestamp or datetime.now().isoformat()
        self.importance = self.metadata.get('importance', 0.5)  # 0-1ï¼Œé‡è¦æ€§è¯„åˆ†


class EnhancedMemoryManager:
    """å¢å¼ºå‹è®°å¿†ç®¡ç†å™¨
    
    å‚è€ƒ Mem0 è®¾è®¡ç†å¿µï¼š
    - å¤šçº§è®°å¿†ï¼ˆç”¨æˆ·/ä¼šè¯/ä¸Šä¸‹æ–‡ï¼‰
    - æ™ºèƒ½æ£€ç´¢å’Œè¿‡æ»¤
    - è®°å¿†é‡è¦æ€§è¯„åˆ†
    - æŒä¹…åŒ–å­˜å‚¨
    """
    
    def __init__(self, user_id: str = "default", storage_dir: Optional[Path] = None, memory_compressor=None,
                 embedding_service: Optional[EmbeddingService] = None, db_client=None):
        """åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
        
        Args:
            user_id: ç”¨æˆ·IDï¼ˆç”¨äºç”¨æˆ·çº§è®°å¿†ï¼‰
            storage_dir: å­˜å‚¨ç›®å½•ï¼ˆç”¨äºæŒä¹…åŒ–ï¼‰
            memory_compressor: è®°å¿†å‹ç¼©å™¨å®ä¾‹ï¼ˆå¯é€‰ï¼‰
            embedding_service: åµŒå…¥æœåŠ¡å®ä¾‹ï¼ˆç”¨äºå‘é‡åŒ–ï¼‰
            db_client: ChromaDB å®¢æˆ·ç«¯å®ä¾‹ï¼ˆç”¨äºå‘é‡å­˜å‚¨ï¼‰
        """
        self.user_id = user_id
        self.logger = _get_logger()  # å»¶è¿Ÿè·å– logger
        
        # å­˜å‚¨ç›®å½•
        if storage_dir:
            self.storage_dir = Path(storage_dir)
            self.storage_dir.mkdir(parents=True, exist_ok=True)
        else:
            from core.utils.path_utils import PathUtils
            path_utils = PathUtils()
            self.storage_dir = path_utils.get_user_data_dir() / "ai_memory"
            self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        self.memory_file = self.storage_dir / f"{user_id}_memory.json"
        
        # è®°å¿†å­˜å‚¨
        self.user_memories: List[Memory] = []      # ç”¨æˆ·çº§ï¼ˆæŒä¹…åŒ–ï¼‰
        self.session_memories: List[Memory] = []   # ä¼šè¯çº§ï¼ˆä¸´æ—¶ï¼‰
        self.context_buffer = deque(maxlen=10)     # ä¸Šä¸‹æ–‡ç¼“å†²ï¼ˆæœ€è¿‘10è½®ï¼‰
        self.compressed_summary: Optional[str] = None  # å‹ç¼©åçš„å†å²æ‘˜è¦
        
        # è®°å¿†å‹ç¼©å™¨
        self.memory_compressor = memory_compressor
        
        # å‘é‡æ£€ç´¢æ”¯æŒ
        self.embedding_service = embedding_service or EmbeddingService()
        self.db_client = db_client
        self._memory_collection = None
        
        # åˆå§‹åŒ– ChromaDB é›†åˆï¼ˆå¦‚æœæä¾›äº† db_clientï¼‰
        try:
            if self.db_client is not None:
                self._init_memory_collection()
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ– ChromaDB é›†åˆæ—¶å‡ºé”™ï¼ˆéè‡´å‘½ï¼‰: {e}", exc_info=True)
            self._memory_collection = None
        
        # åŠ è½½æŒä¹…åŒ–è®°å¿†
        try:
            self._load_user_memories()
        except Exception as e:
            self.logger.error(f"åŠ è½½ç”¨æˆ·è®°å¿†æ—¶å‡ºé”™ï¼ˆéè‡´å‘½ï¼‰: {e}", exc_info=True)
        
        self.logger.info(f"å¢å¼ºå‹è®°å¿†ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼ˆç”¨æˆ·: {user_id}ï¼Œå‘é‡æ£€ç´¢: {'å·²å¯ç”¨' if self._memory_collection else 'æœªå¯ç”¨'}ï¼‰")
    
    def _init_memory_collection(self):
        """åˆå§‹åŒ– ChromaDB è®°å¿†é›†åˆ"""
        if self.db_client is None:
            return
        
        try:
            # åˆ›å»ºåµŒå…¥å‡½æ•°åŒ…è£…å™¨ï¼ˆä½¿ç”¨æœ¬åœ°å®šä¹‰çš„ç±»ï¼Œé¿å…å¾ªç¯ä¾èµ–ï¼‰
            embedding_func = BGEEmbeddingFunctionForMemory(self.embedding_service)
            
            # è·å–æˆ–åˆ›å»ºè®°å¿†é›†åˆï¼ˆä½¿ç”¨ get_or_createï¼Œè®© ChromaDB å¤„ç†å†²çªï¼‰
            self._memory_collection = self.db_client.get_or_create_collection(
                name=f"user_memory_{self.user_id}",
                metadata={"description": f"User memory for {self.user_id} (bge-small-zh-v1.5)"},
                embedding_function=embedding_func
            )
            self.logger.info(f"è®°å¿†é›†åˆå·²å°±ç»ª: user_memory_{self.user_id}")
            
            # ä¸è°ƒç”¨ count()ï¼Œé¿å…è§¦å‘å´©æºƒ
            self.logger.info(f"ChromaDB è®°å¿†é›†åˆåˆå§‹åŒ–æˆåŠŸ: user_memory_{self.user_id}")
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ– ChromaDB è®°å¿†é›†åˆå¤±è´¥: {e}", exc_info=True)
            self._memory_collection = None
    
    def add_memory(self, content: str, level: str = MemoryLevel.SESSION, 
                   metadata: Optional[Dict] = None, auto_evaluate: bool = True):
        """æ·»åŠ è®°å¿†
        
        Args:
            content: è®°å¿†å†…å®¹
            level: è®°å¿†çº§åˆ«
            metadata: å…ƒæ•°æ®ï¼ˆå¦‚ç±»å‹ã€æ ‡ç­¾ç­‰ï¼‰
            auto_evaluate: æ˜¯å¦è‡ªåŠ¨è¯„ä¼°é‡è¦æ€§
        """
        memory = Memory(content, level, metadata)
        
        # è‡ªåŠ¨è¯„ä¼°é‡è¦æ€§ï¼ˆç®€å•è§„åˆ™ï¼Œå¯æ‰©å±•ä¸º AI è¯„ä¼°ï¼‰
        if auto_evaluate:
            memory.importance = self._evaluate_importance(content, metadata)
        
        # æ ¹æ®çº§åˆ«æ·»åŠ åˆ°å¯¹åº”å­˜å‚¨
        if level == MemoryLevel.USER:
            self.user_memories.append(memory)
            self._save_user_memories()  # æŒä¹…åŒ–åˆ° JSONï¼ˆå†·å¤‡ä»½ï¼‰
            
            # åŒæ—¶å­˜å‚¨åˆ° ChromaDB å‘é‡æ•°æ®åº“
            if self._memory_collection is not None:
                try:
                    # ç”Ÿæˆå”¯ä¸€ ID
                    memory_id = f"{self.user_id}_{memory.timestamp}_{hash(content) % 100000}"
                    
                    # å‡†å¤‡å…ƒæ•°æ®
                    chroma_metadata = {
                        'timestamp': memory.timestamp,
                        'importance': memory.importance,
                        'level': level,
                        'user_id': self.user_id
                    }
                    # åˆå¹¶ç”¨æˆ·æä¾›çš„å…ƒæ•°æ®
                    if metadata:
                        chroma_metadata.update({k: str(v) for k, v in metadata.items()})
                    
                    # å­˜å…¥ ChromaDBï¼ˆä¼šè‡ªåŠ¨å‘é‡åŒ–ï¼‰
                    self._memory_collection.upsert(
                        ids=[memory_id],
                        documents=[content],
                        metadatas=[chroma_metadata]
                    )
                    
                    self.logger.debug(f"è®°å¿†å·²å‘é‡åŒ–å¹¶å­˜å…¥ ChromaDB: {memory_id}")
                    
                except Exception as e:
                    self.logger.error(f"å­˜å‚¨è®°å¿†åˆ° ChromaDB å¤±è´¥: {e}", exc_info=True)
        
        elif level == MemoryLevel.SESSION:
            self.session_memories.append(memory)
        elif level == MemoryLevel.CONTEXT:
            self.context_buffer.append(memory)
        
        self.logger.debug(f"æ·»åŠ è®°å¿† [{level}]: {content[:50]}... (é‡è¦æ€§: {memory.importance:.2f})")
    
    def add_dialogue(self, user_query, assistant_response: str, 
                    auto_classify: bool = True):
        """æ·»åŠ å¯¹è¯åˆ°è®°å¿†
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            assistant_response: AI å›å¤
            auto_classify: æ˜¯å¦è‡ªåŠ¨åˆ†ç±»é‡è¦æ€§å¹¶é€‰æ‹©å­˜å‚¨çº§åˆ«
        """
        # å¤„ç†åˆ—è¡¨ç±»å‹çš„ user_query
        if isinstance(user_query, list):
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            user_query_text = " ".join(str(item.get("text", item)) if isinstance(item, dict) else str(item) for item in user_query)
        else:
            user_query_text = str(user_query)
        
        # æ·»åŠ ç”¨æˆ·æŸ¥è¯¢
        metadata_user = {'type': 'user_query'}
        level = MemoryLevel.CONTEXT  # é»˜è®¤ä¸Šä¸‹æ–‡çº§
        
        if auto_classify:
            # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦å€¼å¾—é•¿æœŸä¿å­˜
            if self._is_important_query(user_query_text):
                level = MemoryLevel.USER
                metadata_user['tags'] = ['é‡è¦æŸ¥è¯¢']
                self.logger.info(f"[é‡è¦æŸ¥è¯¢] ä¿å­˜åˆ°ç”¨æˆ·çº§è®°å¿†: {user_query_text[:50]}...")
        
        self.add_memory(f"ç”¨æˆ·: {user_query_text}", level, metadata_user)
        
        # æ·»åŠ  AI å›å¤ï¼ˆç²¾ç®€ç‰ˆï¼‰
        response_summary = assistant_response[:200] + "..." if len(assistant_response) > 200 else assistant_response
        metadata_assistant = {'type': 'assistant_response'}
        self.add_memory(f"åŠ©æ‰‹: {response_summary}", MemoryLevel.CONTEXT, metadata_assistant)
        
        self.logger.info(f"[å¯¹è¯å·²ä¿å­˜] ç”¨æˆ·çº§:{len(self.user_memories)}, ä¼šè¯çº§:{len(self.session_memories)}, ä¸Šä¸‹æ–‡:{len(self.context_buffer)}")
    
    def get_relevant_memories(self, query: str, limit: int = 5, 
                             min_importance: float = 0.3) -> List[str]:
        """è·å–ç›¸å…³è®°å¿†ï¼ˆåŸºäºå‘é‡è¯­ä¹‰æ£€ç´¢ï¼‰
        
        Args:
            query: æŸ¥è¯¢å†…å®¹
            limit: è¿”å›æ•°é‡é™åˆ¶
            min_importance: æœ€å°é‡è¦æ€§é˜ˆå€¼
            
        Returns:
            List[str]: ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        self.logger.info(f"[è®°å¿†æ£€ç´¢] æŸ¥è¯¢: '{query[:50]}...'")
        
        results = []
        
        # 1. ä» ChromaDB å‘é‡æ£€ç´¢ç”¨æˆ·çº§è®°å¿†ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
        if self._memory_collection is not None:
            try:
                self.logger.info("ğŸ”® [å‘é‡æ£€ç´¢] å¯åŠ¨ ChromaDB è¯­ä¹‰æœç´¢...")
                
                # ä½¿ç”¨å‘é‡ç›¸ä¼¼åº¦æœç´¢
                search_results = self._memory_collection.query(
                    query_texts=[query],
                    n_results=min(limit, 10),  # å¤šå–ä¸€äº›å¤‡é€‰
                    where={"user_id": self.user_id}  # è¿‡æ»¤å½“å‰ç”¨æˆ·
                )
                
                if search_results['documents'] and len(search_results['documents']) > 0:
                    for i, content in enumerate(search_results['documents'][0]):
                        metadata = search_results['metadatas'][0][i] if search_results['metadatas'] else {}
                        distance = search_results['distances'][0][i] if search_results['distances'] else 1.0
                        importance = float(metadata.get('importance', 0.5))
                        
                        # è¿‡æ»¤ä½é‡è¦æ€§è®°å¿†
                        if importance < min_importance:
                            continue
                        
                        # å‘é‡ç›¸ä¼¼åº¦å¾—åˆ†ï¼ˆè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼‰
                        similarity_score = 1.0 - distance
                        
                        results.append((content, similarity_score, 'vector_user'))
                        
                    self.logger.info(f"âœ… [å‘é‡æ£€ç´¢] ChromaDB æˆåŠŸæ£€ç´¢åˆ° {len(results)} æ¡è®°å¿†ï¼ˆè¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ï¼‰")
                else:
                    self.logger.info("âš ï¸ [å‘é‡æ£€ç´¢] ChromaDB æœªæ‰¾åˆ°åŒ¹é…è®°å¿†")
            
            except Exception as e:
                self.logger.error(f"âŒ [å‘é‡æ£€ç´¢] ChromaDB æ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        else:
            self.logger.warning("âš ï¸ [å‘é‡æ£€ç´¢] ChromaDB æœªå¯ç”¨ï¼Œè·³è¿‡å‘é‡æ£€ç´¢")
        
        # 2. ä»ä¼šè¯çº§å’Œä¸Šä¸‹æ–‡çº§è®°å¿†ä¸­æ£€ç´¢ï¼ˆå…³é”®è¯åŒ¹é…ä½œä¸ºè¡¥å……ï¼‰
        self.logger.info("ğŸ” [å…³é”®è¯æ£€ç´¢] æ‰«æä¼šè¯çº§å’Œä¸Šä¸‹æ–‡çº§è®°å¿†...")
        query_lower = query.lower()
        query_words = [w for w in query_lower.split() if len(w) > 1]
        
        # ä¼šè¯çº§è®°å¿†
        for memory in self.session_memories:
            if memory.importance < min_importance:
                continue
            
            content_lower = memory.content.lower()
            matches = sum(1 for word in query_words if word in content_lower)
            
            if matches > 0:
                score = matches * 0.5 + memory.importance * 0.3
                results.append((memory.content, score, 'keyword_session'))
        
        # ä¸Šä¸‹æ–‡çº§è®°å¿†ï¼ˆæœ€è¿‘å¯¹è¯ï¼‰
        for memory in list(self.context_buffer):
            content_lower = memory.content.lower()
            matches = sum(1 for word in query_words if word in content_lower)
            
            if matches > 0:
                score = matches * 0.3 + memory.importance * 0.2
                results.append((memory.content, score, 'keyword_context'))
        
        # 3. åˆå¹¶å¹¶æ’åºç»“æœ
        results.sort(key=lambda x: x[1], reverse=True)
        
        # è°ƒè¯•æ—¥å¿—
        self.logger.info(f"[è®°å¿†æ£€ç´¢] å…±æ‰¾åˆ° {len(results)} æ¡ç›¸å…³è®°å¿†")
        self.logger.info(f"[è®°å¿†è¯„åˆ†] å‰ {min(5, len(results))} æ¡è®°å¿†:")
        for i, (content, score, source) in enumerate(results[:5], 1):
            self.logger.info(f"  {i}. [{source}] è¯„åˆ†:{score:.2f} | {content[:60]}...")
        
        # è¿”å›å‰ N æ¡
        return [content for content, score, source in results[:limit]]
    
    def get_recent_context(self, limit: int = 5) -> str:
        """è·å–æœ€è¿‘çš„ä¸Šä¸‹æ–‡ï¼ˆæ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼‰
        
        Args:
            limit: è·å–æ•°é‡
            
        Returns:
            str: æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å‹ç¼©æ‘˜è¦ï¼‰
        """
        formatted = []
        
        # å¦‚æœæœ‰å‹ç¼©æ‘˜è¦ï¼Œå…ˆæ·»åŠ 
        if self.compressed_summary:
            formatted.append(self.compressed_summary)
        
        # æ·»åŠ æœ€è¿‘çš„åŸå§‹å¯¹è¯
        recent = list(self.context_buffer)[-limit:]
        if recent:
            formatted.append("[æœ€è¿‘å¯¹è¯ä¸Šä¸‹æ–‡]")
            for memory in recent:
                formatted.append(memory.content)
        
        return "\n".join(formatted) if formatted else ""
    
    def get_user_identity(self) -> str:
        """è·å–ç”¨æˆ·èº«ä»½ä¿¡æ¯ï¼ˆåº”è¯¥èå…¥AIè§’è‰²è®¾å®šçš„è®°å¿†ï¼‰
        
        ä»ç”¨æˆ·çº§è®°å¿†ä¸­æå–èº«ä»½ã€è§’è‰²ã€äººè®¾ç›¸å…³çš„ä¿¡æ¯
        
        Returns:
            str: ç”¨æˆ·èº«ä»½ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        if not self.user_memories:
            return ""
        
        # æ£€ç´¢èº«ä»½ç›¸å…³çš„è®°å¿†ï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…è§„åˆ™ï¼‰
        # åªåŒ¹é…æ˜ç¡®çš„èº«ä»½è®¾å®šè¯­å¥ï¼Œé¿å…åŒ¹é…æ™®é€šå¯¹è¯
        identity_patterns = [
            'ä»ç°åœ¨å¼€å§‹ä½ æ˜¯',
            'ä»ç°åœ¨å¼€å§‹ä½ ä¸æ˜¯', 
            'ä½ ç°åœ¨æ˜¯',
            'æ‰®æ¼”çŒ«å¨˜',
            'ä½ æ˜¯çŒ«å¨˜',
            'ä¸æ˜¯çŒ«å¨˜äº†',
            'æ¢å¤ä½ çš„åŸæ¥èº«ä»½',
            'ä½ çš„èº«ä»½æ˜¯',
            'ä½ çš„è§’è‰²æ˜¯'
        ]
        identity_memories = []
        
        # åªæ£€æŸ¥ç”¨æˆ·çº§è®°å¿†ï¼ˆMemoryç±»å‹ï¼‰ä¸­æ ‡è®°ä¸º"ç”¨æˆ·ç›¸å…³ä¿¡æ¯"çš„è®°å¿†
        for memory in self.user_memories:
            content = memory.content
            # å¿…é¡»åŒæ—¶æ»¡è¶³ï¼š1) åŒ…å«"ç”¨æˆ·ç›¸å…³ä¿¡æ¯"æˆ–"ç”¨æˆ·åå¥½" 2) åŒ…å«èº«ä»½è®¾å®šçŸ­è¯­
            is_user_info = content.startswith("ç”¨æˆ·ç›¸å…³ä¿¡æ¯:") or content.startswith("ç”¨æˆ·åå¥½:")
            has_identity_pattern = any(pattern in content for pattern in identity_patterns)
            
            if is_user_info and has_identity_pattern:
                identity_memories.append(memory)
        
        if not identity_memories:
            return ""
        
        # è¿”å›æœ€æ–°çš„èº«ä»½è®°å¿†ï¼ˆæŒ‰æ—¶é—´æˆ³æ’åºï¼Œåªå–æœ€åä¸€æ¡ï¼‰
        # é¿å…è¿”å›å¤šæ¡çŸ›ç›¾çš„èº«ä»½è®¾å®š
        identity_memories.sort(key=lambda m: m.timestamp)
        latest_identity = identity_memories[-1].content
        return latest_identity  # åªè¿”å›æœ€æ–°çš„1æ¡èº«ä»½è®°å¿†
    
    def get_user_profile(self) -> str:
        """è·å–ç”¨æˆ·ç”»åƒï¼ˆä»ç”¨æˆ·çº§è®°å¿†ä¸­æå–ï¼Œæ’é™¤èº«ä»½ä¿¡æ¯ï¼‰
        
        Returns:
            str: ç”¨æˆ·ç”»åƒä¿¡æ¯
        """
        if not self.user_memories:
            return ""
        
        # æå–é«˜é‡è¦æ€§è®°å¿†ï¼Œä½†æ’é™¤èº«ä»½ç›¸å…³çš„ï¼ˆé¿å…é‡å¤ï¼‰
        identity_keywords = ['çŒ«å¨˜', 'èº«ä»½', 'æˆ‘æ˜¯', 'å«æˆ‘', 'è§’è‰²', 'äººè®¾', 'å–µ']
        important_memories = [
            m for m in self.user_memories 
            if m.importance > 0.7 and not any(keyword in m.content.lower() for keyword in identity_keywords)
        ]
        
        if not important_memories:
            return ""
        
        profile = ["[ç”¨æˆ·ä¹ æƒ¯å’Œåå¥½]"]
        for memory in important_memories[-5:]:  # æœ€è¿‘5æ¡é‡è¦è®°å¿†
            profile.append(f"- {memory.content}")
        
        return "\n".join(profile)
    
    def compress_old_context(self, conversation_history: List[Dict[str, str]]) -> bool:
        """å‹ç¼©æ—§å¯¹è¯å†å²ä¸ºæ‘˜è¦
        
        å½“å¯¹è¯å†å²è¿‡é•¿æ—¶ï¼Œè‡ªåŠ¨è§¦å‘å‹ç¼©ï¼Œå°†æ—§æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
        
        Args:
            conversation_history: å®Œæ•´çš„å¯¹è¯å†å²åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸå‹ç¼©
        """
        if not self.memory_compressor:
            self.logger.warning("è®°å¿†å‹ç¼©å™¨æœªè®¾ç½®ï¼Œæ— æ³•å‹ç¼©")
            return False
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‹ç¼©
        if not self.memory_compressor.should_compress(len(conversation_history)):
            return False
        
        try:
            # è·å–éœ€è¦å‹ç¼©çš„æ—§æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘çš„å‡ æ¡ï¼‰
            keep_recent = self.memory_compressor.keep_recent
            old_messages = conversation_history[:-keep_recent] if len(conversation_history) > keep_recent else []
            
            if not old_messages:
                return False
            
            # ç”Ÿæˆå‹ç¼©æ‘˜è¦
            summary = self.memory_compressor.compress_history(old_messages)
            
            if summary:
                self.compressed_summary = summary
                self.logger.info(f"âœ… æˆåŠŸå‹ç¼© {len(old_messages)} æ¡å†å²æ¶ˆæ¯")
                return True
            
            return False
        
        except Exception as e:
            self.logger.error(f"å‹ç¼©å†å²æ—¶å‡ºé”™: {e}", exc_info=True)
            return False
    
    def clear_session(self):
        """æ¸…ç©ºä¼šè¯çº§è®°å¿†"""
        self.session_memories.clear()
        self.context_buffer.clear()
        self.compressed_summary = None  # æ¸…ç©ºå‹ç¼©æ‘˜è¦
        self.logger.info("ä¼šè¯è®°å¿†å·²æ¸…ç©º")
    
    def _evaluate_importance(self, content: str, metadata: Optional[Dict] = None) -> float:
        """è¯„ä¼°è®°å¿†é‡è¦æ€§ï¼ˆç®€å•è§„åˆ™ï¼Œå¯æ‰©å±•ä¸º AI è¯„åˆ†ï¼‰
        
        Args:
            content: å†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            float: é‡è¦æ€§è¯„åˆ† (0-1)
        """
        score = 0.5  # é»˜è®¤ä¸­ç­‰é‡è¦æ€§
        
        # è§„åˆ™1ï¼šåŒ…å«ç‰¹å®šå…³é”®è¯æå‡é‡è¦æ€§
        important_keywords = ['é”™è¯¯', 'é…ç½®', 'è·¯å¾„', 'æ–‡ä»¶', 'èµ„äº§', 'è®¾ç½®', 'é—®é¢˜']
        content_lower = content.lower()
        matches = sum(1 for keyword in important_keywords if keyword in content_lower)
        score += matches * 0.1
        
        # è§„åˆ™2ï¼šå†…å®¹é•¿åº¦ï¼ˆè¿‡é•¿æˆ–è¿‡çŸ­é™ä½é‡è¦æ€§ï¼‰
        if 20 < len(content) < 200:
            score += 0.1
        
        # è§„åˆ™3ï¼šå…ƒæ•°æ®æ ‡ç­¾
        if metadata and 'tags' in metadata:
            if 'é‡è¦' in str(metadata['tags']):
                score += 0.2
        
        return min(1.0, max(0.0, score))
    
    def _is_important_query(self, query) -> bool:
        """åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦é‡è¦ï¼ˆå€¼å¾—é•¿æœŸä¿å­˜ï¼‰
        
        Args:
            query: æŸ¥è¯¢å†…å®¹ï¼ˆå­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
            
        Returns:
            bool: æ˜¯å¦é‡è¦
        """
        # å¤„ç†åˆ—è¡¨ç±»å‹ï¼ˆå¤šéƒ¨åˆ†æ¶ˆæ¯ï¼‰
        if isinstance(query, list):
            # æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            query_text = " ".join(str(item.get("text", item)) if isinstance(item, dict) else str(item) for item in query)
        else:
            query_text = str(query)
        
        # åŒ…å«ç‰¹å®šå…³é”®è¯çš„æŸ¥è¯¢è§†ä¸ºé‡è¦
        important_indicators = ['æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'é…ç½®', 'è®¾ç½®', 'é—®é¢˜', 'é”™è¯¯']
        query_lower = query_text.lower()
        
        return any(indicator in query_lower for indicator in important_indicators)
    
    def _load_user_memories(self):
        """ä»æ–‡ä»¶åŠ è½½ç”¨æˆ·çº§è®°å¿†"""
        try:
            if self.memory_file.exists():
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                for item in data.get('memories', []):
                    memory = Memory(
                        content=item['content'],
                        level=MemoryLevel.USER,
                        metadata=item.get('metadata', {}),
                        timestamp=item.get('timestamp')
                    )
                    memory.importance = item.get('importance', 0.5)
                    self.user_memories.append(memory)
                
                self.logger.info(f"åŠ è½½äº† {len(self.user_memories)} æ¡ç”¨æˆ·è®°å¿†")
        
        except Exception as e:
            self.logger.error(f"åŠ è½½ç”¨æˆ·è®°å¿†å¤±è´¥: {e}")
    
    def _save_user_memories(self):
        """ä¿å­˜ç”¨æˆ·çº§è®°å¿†åˆ°æ–‡ä»¶"""
        try:
            data = {
                'user_id': self.user_id,
                'updated_at': datetime.now().isoformat(),
                'memories': [
                    {
                        'content': m.content,
                        'importance': m.importance,
                        'metadata': m.metadata,
                        'timestamp': m.timestamp
                    }
                    for m in self.user_memories
                ]
            }
            
            with open(self.memory_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            self.logger.debug(f"ä¿å­˜äº† {len(self.user_memories)} æ¡ç”¨æˆ·è®°å¿†")
        
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç”¨æˆ·è®°å¿†å¤±è´¥: {e}")

